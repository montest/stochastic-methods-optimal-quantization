{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montest/stochastic-methods-optimal-quantization/blob/pytorch_implentation_dim_1/Lloyd_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YMZltcoG1xX3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import itertools\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "np.set_printoptions(threshold=np.inf, linewidth=10_000)\n",
        "torch.set_printoptions(profile=\"full\", linewidth=10_000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimized numpy implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UZYmsd5F10hG"
      },
      "outputs": [],
      "source": [
        "def lloyd_method_dim_1(N: int, M: int, nbr_iter: int, seed: int = 0):\n",
        "    \"\"\"\n",
        "    Apply `nbr_iter` iterations of the Randomized Lloyd algorithm in order to build an optimal quantizer of size `N`\n",
        "    for a Gaussian random variable. This implementation is done using numpy.\n",
        "\n",
        "    N: number of centroids\n",
        "    M: number of samples to generate\n",
        "    nbr_iter: number of iterations of fixed point search\n",
        "    seed: numpy seed for reproducibility\n",
        "\n",
        "    Returns: centroids, probabilities associated to each centroid and distortion\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)  # Set seed in order to be able to reproduce the results\n",
        "\n",
        "    # Draw M samples of gaussian variable\n",
        "    xs = np.random.normal(0, 1, size=M)\n",
        "\n",
        "    # Initialize the Voronoi Quantizer randomly and sort it\n",
        "    centroids = np.random.normal(0, 1, size=N)\n",
        "    centroids.sort(axis=0)\n",
        "\n",
        "    with trange(nbr_iter, desc=f'Lloyd method - N: {N} - M: {M} - seed: {seed} (numpy)') as t:\n",
        "        for step in t:\n",
        "            # Compute the vertices that separate the centroids\n",
        "            vertices = 0.5 * (centroids[:-1] + centroids[1:])\n",
        "\n",
        "            # Find the index of the centroid that is closest to each sample\n",
        "            index_closest_centroid = np.sum(xs[:, None] >= vertices[None, :], axis=1)\n",
        "\n",
        "            # Compute the new quantization levels as the mean of the samples assigned to each level\n",
        "            centroids = np.array([np.mean(xs[index_closest_centroid == i], axis=0) for i in range(N)])\n",
        "\n",
        "            if any(np.isnan(centroids)):\n",
        "                break\n",
        "\n",
        "    # Compute, for each sample, the distance to each centroid\n",
        "    dist_centroids_points = np.linalg.norm(centroids.reshape((N, 1)) - xs.reshape(M, 1, 1), axis=2)\n",
        "    # Find the index of the centroid that is closest to each sample using the previously computed distances\n",
        "    index_closest_centroid = dist_centroids_points.argmin(axis=1)\n",
        "    # Compute the probability of each centroid\n",
        "    probabilities = np.bincount(index_closest_centroid) / float(M)\n",
        "    # Compute the final distortion between the samples and the quantizer\n",
        "    distortion = np.mean(dist_centroids_points[np.arange(M), index_closest_centroid] ** 2) * 0.5\n",
        "    return centroids, probabilities, distortion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtbwMaS_18EE",
        "outputId": "6e49c8c1-12b3-4a41-8692-8534bf4dfde3"
      },
      "outputs": [],
      "source": [
        "def lloyd_method_dim_1_pytorch(N: int, M: int, nbr_iter: int, device: str, seed: int = 0):\n",
        "    \"\"\"\n",
        "    Apply `nbr_iter` iterations of the Randomized Lloyd algorithm in order to build an optimal quantizer of size `N`\n",
        "    for a Gaussian random variable. This implementation is done using torch.\n",
        "\n",
        "    N: number of centroids\n",
        "    M: number of samples to generate\n",
        "    nbr_iter: number of iterations of fixed point search\n",
        "    device: device on which perform the computations: \"cuda\" or \"cpu\"\n",
        "    seed: torch seed for reproducibility\n",
        "\n",
        "    Returns: centroids, probabilities associated to each centroid and distortion\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed=seed)  # Set seed in order to be able to reproduce the results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Draw M samples of gaussian variable\n",
        "        xs = torch.randn(M)\n",
        "        # xs = torch.tensor(torch.randn(M), dtype=torch.float32)\n",
        "        xs = xs.to(device)  # send samples to correct device\n",
        "\n",
        "        # Initialize the Voronoi Quantizer randomly\n",
        "        centroids = torch.randn(N)\n",
        "        centroids, index = centroids.sort()\n",
        "        centroids = centroids.to(device)  # send centroids to correct device\n",
        "\n",
        "        with trange(nbr_iter, desc=f'Lloyd method - N: {N} - M: {M} - seed: {seed} (pytorch: {device})') as t:\n",
        "            for step in t:\n",
        "                # Compute the vertices that separate the centroids\n",
        "                vertices = 0.5 * (centroids[:-1] + centroids[1:])\n",
        "\n",
        "                # Find the index of the centroid that is closest to each sample\n",
        "                index_closest_centroid = torch.sum(xs[:, None] >= vertices[None, :], dim=1).long()\n",
        "\n",
        "                # Compute the new quantization levels as the mean of the samples assigned to each level\n",
        "                centroids = torch.tensor([torch.mean(xs[index_closest_centroid == i]) for i in range(N)]).to(device)\n",
        "\n",
        "                if torch.isnan(centroids).any():\n",
        "                    break\n",
        "\n",
        "        # Compute, for each sample, the distance to each centroid\n",
        "        dist_centroids_points = torch.norm(centroids - xs.reshape(M, 1, 1), dim=1)\n",
        "        # Find the index of the centroid that is closest to each sample using the previously computed distances\n",
        "        index_closest_centroid = dist_centroids_points.argmin(dim=1)\n",
        "        # Compute the probability of each centroid\n",
        "        probabilities = torch.bincount(index_closest_centroid).to('cpu').numpy()/float(M)\n",
        "        # Compute the final distortion between the samples and the quantizer\n",
        "        distortion = torch.mean(dist_centroids_points[torch.arange(M), index_closest_centroid] ** 2).item() * 0.5\n",
        "        return centroids.to('cpu').numpy(), probabilities, distortion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Some useful functions for benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_existance(dict_of_values, df):\n",
        "    v = df.iloc[:, 0] == df.iloc[:, 0]\n",
        "    for key, value in dict_of_values.items():\n",
        "        v &= (df[key] == value)\n",
        "    return v.any()\n",
        "\n",
        "\n",
        "def testing_method(fct_to_test, parameters_grid: dict, path_to_results: str):\n",
        "    if os.path.exists(path_to_results) and os.path.getsize(path_to_results) > 0:\n",
        "        df_results = pd.read_csv(path_to_results, index_col=0)\n",
        "    else:\n",
        "        df_results = pd.DataFrame()\n",
        "\n",
        "    keys, values = zip(*parameters_grid.items())\n",
        "    permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    for permutations in permutations_dicts:\n",
        "        dict_result = permutations.copy()\n",
        "        dict_result[\"method_name\"] = fct_to_test.__name__\n",
        "        if len(df_results) > 0 and check_existance(dict_result, df_results):\n",
        "            print(f\"Skipping {dict_result}\")\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        centroids, probabilities, distortion = fct_to_test(**permutations)\n",
        "        if math.isnan(distortion):\n",
        "            print(f\"Results for following values {dict_result} were not saved \"\n",
        "                  f\"because an nan was present in the centroids\")\n",
        "            continue\n",
        "        elapsed_time = time.time() - start_time\n",
        "        dict_result[\"elapsed_time\"] = elapsed_time\n",
        "        df_results = pd.concat(\n",
        "            [df_results, pd.DataFrame(dict_result, index=[0])],\n",
        "            ignore_index=True\n",
        "        )\n",
        "        df_results.to_csv(path_to_results)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iUFaCZQp2WJc"
      },
      "outputs": [],
      "source": [
        "# parameters_grid = {\n",
        "#         \"N\": [10, 20, 50, 100, 200, 500],\n",
        "#         \"M\": [5000],\n",
        "#         \"nbr_iter\": [100],\n",
        "#         \"seed\": [0]\n",
        "#     }\n",
        "# path_to_results = \"results_test.csv\"\n",
        "\n",
        "# testing_method(lloyd_method_dim_1, parameters_grid, path_to_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_results = \"results_latest.csv\"\n",
        "if os.path.exists(path_to_results) and os.path.getsize(path_to_results) > 0:\n",
        "  df_results = pd.read_csv(path_to_results, index_col=0)\n",
        "df_results['device'].fillna(\"cpu\", inplace=True)\n",
        "df_results[\"method\"] = df_results.loc[:,\"method_name\"] + \"_\" + df_results.loc[:,\"device\"]\n",
        "df_results[\"method\"].replace(\n",
        "  [\"lloyd_method_dim_1_cpu\", \"lloyd_method_dim_1_pytorch_cpu\", \"lloyd_method_dim_1_pytorch_cuda\"],\n",
        "  [\"numpy_cpu\", \"pytorch_cpu\", \"pytorch_cuda\"],\n",
        "  inplace=True\n",
        "  )\n",
        "df_results[\"elapsed_time_by_iter\"] = df_results.loc[:,\"elapsed_time\"] / df_results.loc[:,\"nbr_iter\"]\n",
        "df_results = df_results[df_results.nbr_iter == 100]\n",
        "df_results.drop(labels=[\"method_name\", \"device\", \"nbr_iter\", \"elapsed_time\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_grouped = df_results.groupby(['N', 'M', 'method'])['elapsed_time_by_iter'].mean()\n",
        "df_grouped = df_grouped.reset_index()\n",
        "df_grouped.to_csv(\"grouped_results_latest.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/thibautmontes/GitHub/stochastic-methods-optimal-quantization/venv/lib/python3.9/site-packages/chromedriver_autoinstaller/110/chromedriver'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from bokeh.io import export_svg, export_png\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.palettes import Viridis\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.transform import dodge\n",
        "import chromedriver_autoinstaller\n",
        "chromedriver_autoinstaller.install() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_results(df_grouped, M):\n",
        "    grouped_by_values = df_grouped.groupby([\"method\", \"M\"]).agg(list).to_dict()\n",
        "    elapsed_times_per_iter_per_method = grouped_by_values.get(\"elapsed_time_by_iter\")\n",
        "    Ns_per_method = grouped_by_values.get(\"N\")\n",
        "\n",
        "    source = ColumnDataSource(\n",
        "        data=dict(\n",
        "                Ns_numpy=Ns_per_method.get((\"numpy_cpu\",M)), numpy_cpu=elapsed_times_per_iter_per_method.get((\"numpy_cpu\",M)),\n",
        "                Ns_pytorch_cpu=Ns_per_method.get((\"pytorch_cpu\",M)), pytorch_cpu=elapsed_times_per_iter_per_method.get((\"pytorch_cpu\",M)),\n",
        "                Ns_pytorch_cuda=Ns_per_method.get((\"pytorch_cuda\",M)), pytorch_cuda=elapsed_times_per_iter_per_method.get((\"pytorch_cuda\",M))\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    color_numpy_cpu = Viridis[3][1]\n",
        "    color_pytorch_cpu = Viridis[3][2]\n",
        "    color_pytorch_cuda = Viridis[3][0]\n",
        "    general_font_size = '14pt'\n",
        "\n",
        "    plot = figure(plot_width=600, plot_height=500)\n",
        "\n",
        "    plot.xaxis.axis_label = \"Grid size (N)\"\n",
        "    plot.xaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    plot.yaxis.axis_label = \"Time elapsed per iter (in seconds)\"\n",
        "    plot.yaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    plot.circle(x='Ns_numpy', y='numpy_cpu', source=source, fill_color=None, line_color=color_numpy_cpu, legend_label='numpy')\n",
        "    plot.line(x='Ns_numpy', y='numpy_cpu', source=source, line_color=color_numpy_cpu, legend_label='numpy')\n",
        "\n",
        "    plot.circle(x='Ns_pytorch_cpu', y='pytorch_cpu', source=source, fill_color=None, line_color=color_pytorch_cpu, legend_label='pytorch (cpu)')\n",
        "    plot.line(x='Ns_pytorch_cpu', y='pytorch_cpu', source=source, line_color=color_pytorch_cpu, legend_label='pytorch (cpu)')\n",
        "\n",
        "    plot.circle(x='Ns_pytorch_cuda', y='pytorch_cuda', source=source, fill_color=color_pytorch_cuda, line_color=color_pytorch_cuda, legend_label='pytorch (cuda)')\n",
        "    plot.line(x='Ns_pytorch_cuda', y='pytorch_cuda', source=source, line_color=color_pytorch_cuda, legend_label='pytorch (cuda)')\n",
        "\n",
        "    # show(plot)\n",
        "    export_png(plot, filename=f\"_output/gaussian/pytorch/method_comparison_M_{M}.png\")\n",
        "    export_svg(plot, filename=f\"_output/gaussian/pytorch/method_comparison_M_{M}.svg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_results(df_grouped=df_grouped, M=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_ratios(df_grouped, M):\n",
        "    color_numpy_cpu = Viridis[3][1]\n",
        "    color_pytorch_cpu = Viridis[3][2]\n",
        "    color_pytorch_cuda = Viridis[3][0]\n",
        "    general_font_size = '14pt'\n",
        "\n",
        "    grouped_by_values = df_grouped.groupby([\"method\", \"M\"]).agg(list).to_dict()\n",
        "    elapsed_times_per_iter_per_method = grouped_by_values.get(\"elapsed_time_by_iter\")\n",
        "    Ns_per_method = grouped_by_values.get(\"N\")\n",
        "    if(Ns_per_method.get(('pytorch_cuda', M)) != Ns_per_method.get(('pytorch_cpu', M)) or Ns_per_method.get(('numpy_cpu', M)) != Ns_per_method.get(('pytorch_cpu', M))):\n",
        "        print(f\"Cannot plot ratios for M equals {M} because N values does not match!!\")\n",
        "        return\n",
        "        \n",
        "    rescaled_comparisons = {\n",
        "        (method, M): np.array(elapsed_times_per_iter_per_method.get((method, M))) / np.array(elapsed_times_per_iter_per_method.get((\"pytorch_cuda\", M)))\n",
        "        for method, M in elapsed_times_per_iter_per_method\n",
        "        }\n",
        "    Ns = Ns_per_method.get((\"pytorch_cuda\", M))\n",
        "    Ns = [str(N) for N in Ns]\n",
        "\n",
        "    plot = figure(x_range=Ns, plot_width=600, plot_height=500)\n",
        "\n",
        "    plot.xaxis.axis_label = \"Grid size (N)\"\n",
        "    plot.xaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    plot.yaxis.axis_label = \"Ratio Time elapsed per iter vs PyTorch cuda\"\n",
        "    plot.yaxis.axis_label_text_font_size = general_font_size\n",
        "        \n",
        "    source = ColumnDataSource(data={\n",
        "        'Ns' : Ns,\n",
        "        'pytorch_cuda' : rescaled_comparisons.get((\"pytorch_cuda\", M)),\n",
        "        'pytorch_cpu' : rescaled_comparisons.get((\"pytorch_cpu\", M)),\n",
        "        'numpy_cpu' : rescaled_comparisons.get((\"numpy_cpu\", M))\n",
        "    })\n",
        "    \n",
        "    plot.vbar(x=dodge('Ns', -0.25, range=plot.x_range), top='pytorch_cuda', source=source, width=0.2, color=color_pytorch_cuda, legend_label=\"pytorch (cuda)\")\n",
        "    plot.vbar(x=dodge('Ns',  0.0,  range=plot.x_range), top='pytorch_cpu', source=source, width=0.2, color=color_pytorch_cpu, legend_label=\"pytorch (cpu)\")\n",
        "    plot.vbar(x=dodge('Ns',  0.25, range=plot.x_range), top='numpy_cpu', source=source, width=0.2, color=color_numpy_cpu, legend_label=\"numpy\")\n",
        "    plot.legend.location = \"top_left\"\n",
        "    \n",
        "    # show(plot)\n",
        "    export_png(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.png\")\n",
        "    export_svg(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.svg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot_ratios(M=10000)\n",
        "# plot_ratios(M=20000)\n",
        "# plot_ratios(M=100000)\n",
        "# plot_ratios(M=500000)\n",
        "plot_ratios(df_grouped=df_grouped, M=100000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def plot_ratios(df_grouped, M):\n",
        "#     color_numpy_cpu = Viridis[3][1]\n",
        "#     color_pytorch_cpu = Viridis[3][2]\n",
        "#     color_pytorch_cuda = Viridis[3][0]\n",
        "#     general_font_size = '14pt'\n",
        "\n",
        "#     grouped_by_values = df_grouped.groupby([\"method\", \"M\"]).agg(list).to_dict()\n",
        "#     elapsed_times_per_iter_per_method = grouped_by_values.get(\"elapsed_time_by_iter\")\n",
        "#     Ns_per_method = grouped_by_values.get(\"N\")\n",
        "\n",
        "#     rescaled_comparisons = {\n",
        "#         (method, M): np.array(elapsed_times_per_iter_per_method.get((method, M))) / np.array(elapsed_times_per_iter_per_method.get((\"pytorch_cuda\", M)))\n",
        "#         for method, M in elapsed_times_per_iter_per_method\n",
        "#         }\n",
        "#     source = ColumnDataSource(\n",
        "#         data=dict(\n",
        "#                 Ns_numpy=[str(N) for N in Ns_per_method.get((\"numpy_cpu\",M))], numpy_cpu=rescaled_comparisons.get((\"numpy_cpu\",M)),\n",
        "#                 Ns_pytorch_cpu=[str(N) for N in Ns_per_method.get((\"pytorch_cpu\",M))], pytorch_cpu=rescaled_comparisons.get((\"pytorch_cpu\",M)),\n",
        "#                 Ns_pytorch_cuda=[str(N) for N in Ns_per_method.get((\"pytorch_cuda\",M))], pytorch_cuda=rescaled_comparisons.get((\"pytorch_cuda\",M))\n",
        "#             )\n",
        "#         )\n",
        "    \n",
        "#     plot = figure(x_range=[str(N) for N in Ns_per_method.get((\"numpy_cpu\",M))], plot_width=600, plot_height=500)\n",
        "\n",
        "#     plot.xaxis.axis_label = \"Grid size (N)\"\n",
        "#     plot.xaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "#     plot.yaxis.axis_label = \"Ratio Time elapsed per iter vs PyTorch cuda\"\n",
        "#     plot.yaxis.axis_label_text_font_size = general_font_size\n",
        "        \n",
        "#     source = ColumnDataSource(data=data)\n",
        "    \n",
        "#     # plot.vbar(x=dodge('Ns_numpy', -0.25, range=\"Ns_numpy\"), top='pytorch_cuda', source=source, width=0.2, color=color_pytorch_cuda, legend_label=\"pytorch (cuda)\")\n",
        "#     # plot.vbar(x=dodge('Ns_pytorch_cpu', 0.0, range=\"Ns_pytorch_cpu\"), top='pytorch_cpu', source=source, width=0.2, color=color_pytorch_cpu, legend_label=\"pytorch (cpu)\")\n",
        "#     # plot.vbar(x=dodge('Ns_pytorch_cuda', 0.25, range=\"Ns_pytorch_cuda\"), top='numpy_cpu', source=source, width=0.2, color=color_numpy_cpu, legend_label=\"numpy\")\n",
        "    \n",
        "#     plot.vbar(x=dodge('Ns_numpy', -0.25, range=plot.x_range), top='pytorch_cuda', source=source, width=0.2, color=color_pytorch_cuda, legend_label=\"pytorch (cuda)\")\n",
        "#     plot.vbar(x=dodge('Ns_pytorch_cpu',  0.0,  range=plot.x_range), top='pytorch_cpu', source=source, width=0.2, color=color_pytorch_cpu, legend_label=\"pytorch (cpu)\")\n",
        "#     plot.vbar(x=dodge('Ns_pytorch_cuda',  0.25, range=plot.x_range), top='numpy_cpu', source=source, width=0.2, color=color_numpy_cpu, legend_label=\"numpy\")\n",
        "#     plot.legend.location = \"top_left\"\n",
        "    \n",
        "#     # show(plot)\n",
        "#     export_png(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.png\")\n",
        "#     export_svg(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.svg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMbMLQnTY0k8H8SqrM60Cxq",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "57269b72aaeabcedf2a03a235d50b7ad8fc0ec0622b65ff8b5d5d56223729a4f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
