{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montest/stochastic-methods-optimal-quantization/blob/pytorch_implentation_dim_1/Lloyd_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "YMZltcoG1xX3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import itertools\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "np.set_printoptions(threshold=np.inf, linewidth=10_000)\n",
        "torch.set_printoptions(profile=\"full\", linewidth=10_000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimized numpy implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "UZYmsd5F10hG"
      },
      "outputs": [],
      "source": [
        "def lloyd_method_dim_1(N: int, M: int, nbr_iter: int, seed: int = 0):\n",
        "    \"\"\"\n",
        "    Apply `nbr_iter` iterations of the Randomized Lloyd algorithm in order to build an optimal quantizer of size `N`\n",
        "    for a Gaussian random variable. This implementation is done using numpy.\n",
        "\n",
        "    N: number of centroids\n",
        "    M: number of samples to generate\n",
        "    nbr_iter: number of iterations of fixed point search\n",
        "    seed: numpy seed for reproducibility\n",
        "\n",
        "    Returns: centroids, probabilities associated to each centroid and distortion\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)  # Set seed in order to be able to reproduce the results\n",
        "\n",
        "    # Draw M samples of gaussian variable\n",
        "    xs = np.random.normal(0, 1, size=M)\n",
        "\n",
        "    # Initialize the Voronoi Quantizer randomly and sort it\n",
        "    centroids = np.random.normal(0, 1, size=N)\n",
        "    centroids.sort(axis=0)\n",
        "\n",
        "    with trange(nbr_iter, desc=f'Lloyd method - N: {N} - M: {M} - seed: {seed} (numpy)') as t:\n",
        "        for step in t:\n",
        "            # Compute the vertices that separate the centroids\n",
        "            vertices = 0.5 * (centroids[:-1] + centroids[1:])\n",
        "\n",
        "            # Find the index of the centroid that is closest to each sample\n",
        "            index_closest_centroid = np.sum(xs[:, None] >= vertices[None, :], axis=1)\n",
        "\n",
        "            # Compute the new quantization levels as the mean of the samples assigned to each level\n",
        "            centroids = np.array([np.mean(xs[index_closest_centroid == i], axis=0) for i in range(N)])\n",
        "\n",
        "            if any(np.isnan(centroids)):\n",
        "                break\n",
        "\n",
        "    # Compute, for each sample, the distance to each centroid\n",
        "    dist_centroids_points = np.linalg.norm(centroids.reshape((N, 1)) - xs.reshape(M, 1, 1), axis=2)\n",
        "    # Find the index of the centroid that is closest to each sample using the previously computed distances\n",
        "    index_closest_centroid = dist_centroids_points.argmin(axis=1)\n",
        "    # Compute the probability of each centroid\n",
        "    probabilities = np.bincount(index_closest_centroid) / float(M)\n",
        "    # Compute the final distortion between the samples and the quantizer\n",
        "    distortion = np.mean(dist_centroids_points[np.arange(M), index_closest_centroid] ** 2) * 0.5\n",
        "    return centroids, probabilities, distortion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtbwMaS_18EE",
        "outputId": "6e49c8c1-12b3-4a41-8692-8534bf4dfde3"
      },
      "outputs": [],
      "source": [
        "def lloyd_method_dim_1_pytorch(N: int, M: int, nbr_iter: int, device: str, seed: int = 0):\n",
        "    \"\"\"\n",
        "    Apply `nbr_iter` iterations of the Randomized Lloyd algorithm in order to build an optimal quantizer of size `N`\n",
        "    for a Gaussian random variable. This implementation is done using torch.\n",
        "\n",
        "    N: number of centroids\n",
        "    M: number of samples to generate\n",
        "    nbr_iter: number of iterations of fixed point search\n",
        "    device: device on which perform the computations: \"cuda\" or \"cpu\"\n",
        "    seed: torch seed for reproducibility\n",
        "\n",
        "    Returns: centroids, probabilities associated to each centroid and distortion\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed=seed)  # Set seed in order to be able to reproduce the results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Draw M samples of gaussian variable\n",
        "        xs = torch.randn(M)\n",
        "        # xs = torch.tensor(torch.randn(M), dtype=torch.float32)\n",
        "        xs = xs.to(device)  # send samples to correct device\n",
        "\n",
        "        # Initialize the Voronoi Quantizer randomly\n",
        "        centroids = torch.randn(N)\n",
        "        centroids, index = centroids.sort()\n",
        "        centroids = centroids.to(device)  # send centroids to correct device\n",
        "\n",
        "        with trange(nbr_iter, desc=f'Lloyd method - N: {N} - M: {M} - seed: {seed} (pytorch: {device})') as t:\n",
        "            for step in t:\n",
        "                # Compute the vertices that separate the centroids\n",
        "                vertices = 0.5 * (centroids[:-1] + centroids[1:])\n",
        "\n",
        "                # Find the index of the centroid that is closest to each sample\n",
        "                index_closest_centroid = torch.sum(xs[:, None] >= vertices[None, :], dim=1).long()\n",
        "\n",
        "                # Compute the new quantization levels as the mean of the samples assigned to each level\n",
        "                centroids = torch.tensor([torch.mean(xs[index_closest_centroid == i]) for i in range(N)]).to(device)\n",
        "\n",
        "                if torch.isnan(centroids).any():\n",
        "                    break\n",
        "\n",
        "        # Compute, for each sample, the distance to each centroid\n",
        "        dist_centroids_points = torch.norm(centroids - xs.reshape(M, 1, 1), dim=1)\n",
        "        # Find the index of the centroid that is closest to each sample using the previously computed distances\n",
        "        index_closest_centroid = dist_centroids_points.argmin(dim=1)\n",
        "        # Compute the probability of each centroid\n",
        "        probabilities = torch.bincount(index_closest_centroid).to('cpu').numpy()/float(M)\n",
        "        # Compute the final distortion between the samples and the quantizer\n",
        "        distortion = torch.mean(dist_centroids_points[torch.arange(M), index_closest_centroid] ** 2).item() * 0.5\n",
        "        return centroids.to('cpu').numpy(), probabilities, distortion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Some useful functions for benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_existance(dict_of_values, df):\n",
        "    v = df.iloc[:, 0] == df.iloc[:, 0]\n",
        "    for key, value in dict_of_values.items():\n",
        "        v &= (df[key] == value)\n",
        "    return v.any()\n",
        "\n",
        "\n",
        "def testing_method(fct_to_test, parameters_grid: dict, path_to_results: str):\n",
        "    if os.path.exists(path_to_results) and os.path.getsize(path_to_results) > 0:\n",
        "        df_results = pd.read_csv(path_to_results, index_col=0)\n",
        "    else:\n",
        "        df_results = pd.DataFrame()\n",
        "\n",
        "    keys, values = zip(*parameters_grid.items())\n",
        "    permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    for permutations in permutations_dicts:\n",
        "        dict_result = permutations.copy()\n",
        "        dict_result[\"method_name\"] = fct_to_test.__name__\n",
        "        if len(df_results) > 0 and check_existance(dict_result, df_results):\n",
        "            print(f\"Skipping {dict_result}\")\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        centroids, probabilities, distortion = fct_to_test(**permutations)\n",
        "        if math.isnan(distortion):\n",
        "            print(f\"Results for following values {dict_result} were not saved \"\n",
        "                  f\"because an nan was present in the centroids\")\n",
        "            continue\n",
        "        elapsed_time = time.time() - start_time\n",
        "        dict_result[\"elapsed_time\"] = elapsed_time\n",
        "        df_results = pd.concat(\n",
        "            [df_results, pd.DataFrame(dict_result, index=[0])],\n",
        "            ignore_index=True\n",
        "        )\n",
        "        df_results.to_csv(path_to_results)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iUFaCZQp2WJc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lloyd method - N: 10 - M: 5000 - seed: 0 (numpy): 100%|██████████| 100/100 [00:00<00:00, 1754.23it/s]\n",
            "Lloyd method - N: 20 - M: 5000 - seed: 0 (numpy): 100%|██████████| 100/100 [00:00<00:00, 1301.20it/s]\n",
            "Lloyd method - N: 50 - M: 5000 - seed: 0 (numpy): 100%|██████████| 100/100 [00:00<00:00, 664.66it/s]\n",
            "Lloyd method - N: 100 - M: 5000 - seed: 0 (numpy): 100%|██████████| 100/100 [00:00<00:00, 402.56it/s]\n",
            "Lloyd method - N: 200 - M: 5000 - seed: 0 (numpy): 100%|██████████| 100/100 [00:00<00:00, 217.98it/s]\n",
            "Lloyd method - N: 500 - M: 5000 - seed: 0 (numpy):   0%|          | 0/100 [00:00<?, ?it/s]/Users/thibautmontes/GitHub/stochastic-methods-optimal-quantization/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/Users/thibautmontes/GitHub/stochastic-methods-optimal-quantization/venv/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Lloyd method - N: 500 - M: 5000 - seed: 0 (numpy):   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for following values {'N': 500, 'M': 5000, 'nbr_iter': 100, 'seed': 0, 'method_name': 'lloyd_method_dim_1'} were not saved because an nan was present in the centroids\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "parameters_grid = {\n",
        "        \"N\": [10, 20, 50, 100, 200, 500],\n",
        "        \"M\": [5000],\n",
        "        \"nbr_iter\": [100],\n",
        "        \"seed\": [0]\n",
        "    }\n",
        "path_to_results = \"results_test.csv\"\n",
        "\n",
        "testing_method(lloyd_method_dim_1, parameters_grid, path_to_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists(path_to_results) and os.path.getsize(path_to_results) > 0:\n",
        "  df_results = pd.read_csv(path_to_results, index_col=0)\n",
        "df_results['device'].fillna(\"cpu\", inplace=True)\n",
        "df_results[\"method\"] = df_results.loc[:,\"method_name\"] + \"_\" + df_results.loc[:,\"device\"]\n",
        "df_results[\"method\"].replace(\n",
        "  [\"lloyd_method_dim_1_cpu\", \"lloyd_method_dim_1_pytorch_cpu\", \"lloyd_method_dim_1_pytorch_cuda\"],\n",
        "  [\"numpy_cpu\", \"pytorch_cpu\", \"pytorch_cuda\"],\n",
        "  inplace=True\n",
        "  )\n",
        "df_results[\"elapsed_time_by_iter\"] = df_results.loc[:,\"elapsed_time\"] / df_results.loc[:,\"nbr_iter\"]\n",
        "df_results = df_results[df_results.nbr_iter == 100]\n",
        "df_results.drop(labels=[\"method_name\", \"device\", \"nbr_iter\", \"elapsed_time\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_grouped = df_results.groupby(['N', 'M', 'method'])['elapsed_time_by_iter'].mean()\n",
        "df_grouped = df_grouped.reset_index()\n",
        "df_grouped.to_csv(\"grouped_results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/thibautmontes/GitHub/stochastic-methods-optimal-quantization/venv/lib/python3.9/site-packages/chromedriver_autoinstaller/110/chromedriver'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from bokeh.io import export_svg, export_png\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.palettes import Viridis\n",
        "from bokeh.plotting import figure, show\n",
        "import chromedriver_autoinstaller\n",
        "chromedriver_autoinstaller.install() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "toto = df_grouped.groupby([\"method\", \"M\"])[\"elapsed_time_by_iter\"].apply(list).to_dict()\n",
        "\n",
        "def plot_results(M):\n",
        "    color_numpy_cpu = Viridis[3][1]\n",
        "    color_pytorch_cpu = Viridis[3][2]\n",
        "    color_pytorch_cuda = Viridis[3][0]\n",
        "    general_font_size = '14pt'\n",
        "\n",
        "    plot = figure(plot_width=600, plot_height=500)\n",
        "\n",
        "    plot.xaxis.axis_label = \"Grid size (N)\"\n",
        "    plot.xaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    plot.yaxis.axis_label = \"Time elapsed per iter (in seconds)\"\n",
        "    plot.yaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    Ns = df_grouped['N'].unique()\n",
        "    Ns = sorted(Ns)\n",
        "    numpy_cpu, pytorch_cpu, pytorch_cuda = toto.get((\"numpy_cpu\",M)), toto.get((\"pytorch_cpu\",M)), toto.get((\"pytorch_cuda\",M))\n",
        "\n",
        "    source = ColumnDataSource(data=dict(Ns=Ns, numpy_cpu=numpy_cpu, pytorch_cpu=pytorch_cpu, pytorch_cuda=pytorch_cuda))\n",
        "\n",
        "    plot.circle(x='Ns', y='numpy_cpu', source=source, fill_color=None, line_color=color_numpy_cpu, legend_label='numpy')\n",
        "    plot.line(x='Ns', y='numpy_cpu', source=source, line_color=color_numpy_cpu, legend_label='numpy')\n",
        "\n",
        "    plot.circle(x='Ns', y='pytorch_cpu', source=source, fill_color=None, line_color=color_pytorch_cpu, legend_label='pytorch (cpu)')\n",
        "    plot.line(x='Ns', y='pytorch_cpu', source=source, line_color=color_pytorch_cpu, legend_label='pytorch (cpu)')\n",
        "\n",
        "    plot.circle(x='Ns', y='pytorch_cuda', source=source, fill_color=color_pytorch_cuda, line_color=color_pytorch_cuda, legend_label='pytorch (cuda)')\n",
        "    plot.line(x='Ns', y='pytorch_cuda', source=source, line_color=color_pytorch_cuda, legend_label='pytorch (cuda)')\n",
        "\n",
        "    # show(plot)\n",
        "    export_png(plot, filename=f\"_output/gaussian/pytorch/method_comparison_M_{M}.png\")\n",
        "    export_svg(plot, filename=f\"_output/gaussian/pytorch/method_comparison_M_{M}.svg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_results(M=10000)\n",
        "plot_results(M=20000)\n",
        "plot_results(M=100000)\n",
        "plot_results(M=500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('numpy_cpu', 10000): [0.87355883 0.68130139 0.55938944 0.58801913 0.53676187 0.41208587]\n",
            "('numpy_cpu', 20000): [1.57276189 1.21758264 0.88277627 0.78496016 0.74150523 0.78572709]\n",
            "('numpy_cpu', 100000): [6.60273571 5.04527401 4.02010785 3.92536147 3.01155591 3.59650244]\n",
            "('numpy_cpu', 500000): [17.97393747 14.53541768 12.71277519 12.85271106 12.34466679 11.69514007]\n",
            "('pytorch_cpu', 10000): [1.07585364 1.00480215 0.93223047 0.88571743 0.87278114 0.91807631]\n",
            "('pytorch_cpu', 20000): [1.79145143 1.69483303 1.59461367 1.59243231 1.68761245 2.43116919]\n",
            "('pytorch_cpu', 100000): [ 6.9531192   6.73015862  7.34045453 11.54551923  9.37061033 11.17992804]\n",
            "('pytorch_cpu', 500000): [23.82478392 29.52839536 33.16441265 35.36173497 37.10590004 37.04354136]\n",
            "('pytorch_cuda', 10000): [1. 1. 1. 1. 1. 1.]\n",
            "('pytorch_cuda', 20000): [1. 1. 1. 1. 1. 1.]\n",
            "('pytorch_cuda', 100000): [1. 1. 1. 1. 1. 1.]\n",
            "('pytorch_cuda', 500000): [1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "titi = df_grouped.groupby([\"method\", \"M\"])[\"elapsed_time_by_iter\"].apply(np.array).to_dict()\n",
        "rescaled_comparisons = {(method, M): titi.get((method, M)) / titi.get((\"pytorch_cuda\", M)) for method, M in titi}\n",
        "for key, values in rescaled_comparisons.items():\n",
        "    print(f\"{key}: {values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bokeh.transform import dodge\n",
        "\n",
        "def plot_ratios(M):\n",
        "    color_numpy_cpu = Viridis[3][1]\n",
        "    color_pytorch_cpu = Viridis[3][2]\n",
        "    color_pytorch_cuda = Viridis[3][0]\n",
        "    general_font_size = '14pt'\n",
        "\n",
        "    plot = figure(plot_width=600, plot_height=500)\n",
        "\n",
        "    plot.xaxis.axis_label = \"Grid size (N)\"\n",
        "    plot.xaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    plot.yaxis.axis_label = \"Ratio Time elapsed per iter vs PyTorch cuda\"\n",
        "    plot.yaxis.axis_label_text_font_size = general_font_size\n",
        "\n",
        "    Ns = sorted(df_grouped['N'].unique())\n",
        "    methods = ['pytorch_cuda', 'pytorch_cpu', 'numpy_cpu']\n",
        "    Ns = [str(N) for N in Ns]\n",
        "    x = [ (N, method) for N in Ns for method in methods ]\n",
        "\n",
        "    data = {\n",
        "        'Ns' : Ns,\n",
        "        'pytorch_cuda' : rescaled_comparisons.get((\"pytorch_cuda\", M)),\n",
        "        'pytorch_cpu' : rescaled_comparisons.get((\"pytorch_cpu\", M)),\n",
        "        'numpy_cpu' : rescaled_comparisons.get((\"numpy_cpu\", M))\n",
        "    }\n",
        "    \n",
        "    source = ColumnDataSource(data=data)\n",
        "    \n",
        "    plot.vbar(x='Ns', top='pytorch_cuda', source=source, width=0.2, color=color_pytorch_cuda, legend_label=\"pytorch (cuda)\")\n",
        "    plot.vbar(x='Ns', top='pytorch_cpu', source=source, width=0.2, color=color_pytorch_cpu, legend_label=\"pytorch (cpu)\")\n",
        "    plot.vbar(x='Ns', top='numpy_cpu', source=source, width=0.2, color=color_numpy_cpu, legend_label=\"numpy\")\n",
        "    \n",
        "    # plot.vbar(x=dodge('Ns', -1, range=plot.x_range), top='pytorch_cuda', source=source, width=10, color=color_pytorch_cuda, legend_label=\"pytorch (cuda)\")\n",
        "    # plot.vbar(x=dodge('Ns',  0.0,  range=plot.x_range), top='pytorch_cpu', source=source, width=10, color=color_pytorch_cpu, legend_label=\"pytorch (cpu)\")\n",
        "    # plot.vbar(x=dodge('Ns',  1, range=plot.x_range), top='numpy_cpu', source=source, width=10, color=color_numpy_cpu, legend_label=\"numpy\")\n",
        "\n",
        "    # show(plot)\n",
        "    export_png(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.png\")\n",
        "    export_svg(plot, filename=f\"_output/gaussian/pytorch/ratio_comparison_M_{M}.svg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_ratios(M=10000)\n",
        "# plot_ratios(M=20000)\n",
        "# plot_ratios(M=100000)\n",
        "# plot_ratios(M=500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMbMLQnTY0k8H8SqrM60Cxq",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "57269b72aaeabcedf2a03a235d50b7ad8fc0ec0622b65ff8b5d5d56223729a4f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
